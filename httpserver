#!/usr/bin/env python3
import argparse
import gzip
import http.client
import os
import pickle
import requests
import socket
import subprocess
import sys
import threading
import time
import logging

CACHE_FILENAME = "cache"
WEBSITE_LIST = "websites.txt"
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# class LatencyServer:

#     def __init__(self, port):
#         self.port = port

#     def start(self):
#         sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
#         sock.bind(("", self.port))
#         sock.listen()

#         while True:
#             conn, addr = sock.accept()
#             threading.Thread(target=self.handle_latency_request, args=(conn, addr)).start()

#     def measure_latency_to_client(self, client_ip, latency = 999999):
#         result = subprocess.run(
#             ["scamper", "-c", f"ping -c 1", "-i", client_ip],
#             stdout=subprocess.PIPE,
#             text=True
#         )
#         lines = result.stdout.splitlines()
#         try: 
#             line = lines[-1]
#             latency = float(line.split()[3].split('/')[1]) # Extract the latency value
#         except: 
#             latency = 999999  
#         return latency

#     def handle_latency_request(self, conn, addr):
#         client_ip = conn.recv(1024).decode()
#         latency = self.measure_latency_to_client(client_ip)
#         conn.sendall(str(latency).encode())


class LatencyServer:

    def __init__(self, port):
        self.port = port

    def start(self):
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.bind(("", self.port))
        sock.listen()

        while True:
            conn, addr = sock.accept()
            threading.Thread(target=self.handle_latency_request, args=(conn, addr)).start()

    def measure_latency_to_client(self, client_ip, latency = 999999):
        with socket.socket(socket.AF_UNIX, socket.SOCK_STREAM) as scamper_sock:
            scamper_sock.connect("/tmp/scamperctrl")
            scamper_sock.sendall(f"ping -c 1 {client_ip}\n".encode())

            data = b""
            while True:
                chunk = scamper_sock.recv(1024)
                if not chunk:
                    break
                data += chunk

            output = data.decode()
            lines = output.splitlines()
            try:
                line = lines[-1]
                latency = float(line.split()[3].split('/')[1])  # Extract the latency value
            except:
                latency = 999999
        return latency

    def handle_latency_request(self, conn, addr):
        client_ip = conn.recv(1024).decode()
        latency = self.measure_latency_to_client(client_ip)
        conn.sendall(str(latency).encode())


class HTTPServer:

    def __init__(self, port, origin):
        self.port = port
        self.origin = origin
        self.cache_manager = CacheManager(origin)

    def start(self):
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.bind(("", self.port))
        sock.listen()

        while True:
            conn, addr = sock.accept()
            data = conn.recv(1024)
            response = self.handle_request(data.decode())
            conn.sendall(response)
            conn.close()

    def handle_request(self, request):
        request_parts = request.split()
        if len(request_parts) < 2:
            return b"HTTP/1.1 400 Bad Request\r\n\r\n"

        path = request_parts[1]

        if path == "/grading/beacon":
            return b"HTTP/1.1 204 No Content\r\n\r\n"
        # Have records in cache
        elif self.cache_manager.is_in_cache(path):
            headers, content = self.cache_manager.get_from_cache(path)
            response_bytes = bytearray()
            response_line = "HTTP/1.1 200 OK\r\n"
            response_bytes.extend(response_line.encode())

            for header, value in headers.items():
                header_line = f"{header}: {value}\r\n"
                response_bytes.extend(header_line.encode())

            response_bytes.extend(b"\r\n")
            response_bytes.extend(content)

            return bytes(response_bytes)
        # otherwise retrieve from origin
        # for invalid path, origin will respond with a 404
        else:
            conn = http.client.HTTPConnection(self.origin)
            # Add the Host header to the request
            headers = {"Host": self.origin}
            conn.request("GET", path, headers=headers)

            response = conn.getresponse()

            response_headers = response.getheaders()
            response_content = response.read()

            response_bytes = bytearray()
            response_line = f"HTTP/1.1 {response.status} {response.reason}\r\n"
            response_bytes.extend(response_line.encode())

            for header, value in response_headers:
                header_line = f"{header}: {value}\r\n"
                response_bytes.extend(header_line.encode())

            response_bytes.extend(b"\r\n")
            response_bytes.extend(response_content)

            return bytes(response_bytes)


class CacheManager:

    def __init__(self, origin, max_cache_size=20 * 1024 * 1024):
        self.origin = origin
        self.max_cache_size = max_cache_size
        self.cache = self.setup_cache()

    def setup_cache(self):
        try:
            # Attempt to load the cache from the file
            with gzip.open(CACHE_FILENAME, "rb") as cache_file:
                cache = pickle.load(cache_file)
        except (FileNotFoundError, pickle.UnpicklingError):
            # If the file is not found or an error occurs, prepare the cache
            cache = self.prepare_cache()
            # Save the cache to a file named 'cache'
            with gzip.open(CACHE_FILENAME, "wb") as cache_file:
                pickle.dump(cache, cache_file)

        return cache

    def prepare_cache(self):
        # Read the content of websites.txt
        with open(WEBSITE_LIST, "r") as file:
            data = file.read()

        # Split the data into lines
        lines = data.splitlines()

        # Split each line by tabs and create a list of lists
        table = [line.split('\t') for line in lines]

        # Modify the article column and create a new list
        modified_table = [[row[0], row[1], row[2].replace(' ', '_')] for row in table]

        cache = {}
        cache_size = 0

        for i in range(1, len(modified_table)):
            rank, views, article = modified_table[i]
            url = f"http://{self.origin}/{article}"

            response = requests.get(url)

            if response.status_code == 200:
                content = response.content
                content_size = len(content)

                if cache_size + content_size <= self.max_cache_size:
                    cache[f"/{article}"] = content
                    cache_size += content_size
                else:
                    break
        return cache

    def is_in_cache(self, path):
        return path in self.cache

    def get_from_cache(self, path):
        content = self.cache[path]
        headers = {
            "Content-Type": "text/html; charset=utf-8",
            "Content-Length": len(content),
            "Cache-Control": "public, max-age=31536000",
        }
        return headers, content



# def write_log(log_entry):
#     with open("log.txt", "a") as log_file:
#         log_file.write(log_entry + "\n")


def main():
    # Parse command line arguments
    parser = argparse.ArgumentParser()
    parser.add_argument('-p', '--port', required=True, help="Port number to bind the HTTP server")
    parser.add_argument('-o', '--origin', required=True, help="Origin server for the CDN")
    args = parser.parse_args()

    latency_port = int(args.port) + 2

    try:
        # Start the latency server
        latency_server = LatencyServer(latency_port)
        threading.Thread(target=latency_server.start).start()

        # Start the HTTP server
        http_server = HTTPServer(int(args.port), args.origin)
        logging.info(f"Starting HTTP server on port {args.port}")
        http_server.start()
    except Exception as e:
        logging.error(f"Error occurred: {e}")


if __name__ == "__main__":
    main()

